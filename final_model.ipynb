{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFu9IF+aoMJOlaSOMUez3z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kasodeep/inheritance-project/blob/main/final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrieve transcript**"
      ],
      "metadata": {
        "id": "IkrfTbj8Phgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf\n",
        "!pip install pytube\n",
        "!pip install youtube-transcript-api\n",
        "!pip install fpdf\n",
        "!pip install youtube_transcript_api"
      ],
      "metadata": {
        "id": "swzPfkGYPfH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from fpdf import *"
      ],
      "metadata": {
        "id": "TSrb3c17NdWD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transcript(youtube_url, output_pdf_path):\n",
        "    video_id = youtube_url.split(\"v=\")[-1]\n",
        "    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "\n",
        "    # Try fetching the manual transcript\n",
        "    try:\n",
        "        transcript = transcript_list.find_manually_created_transcript()\n",
        "        language_code = transcript.language_code  # Save the detected language\n",
        "    except:\n",
        "        # If no manual transcript is found, try fetching an auto-generated transcript in a supported language\n",
        "        try:\n",
        "            generated_transcripts = [trans for trans in transcript_list if trans.is_generated]\n",
        "            transcript = generated_transcripts[0]\n",
        "            language_code = transcript.language_code  # Save the detected language\n",
        "        except:\n",
        "            # If no auto-generated transcript is found, raise an exception\n",
        "            raise Exception(\"No suitable transcript found.\")\n",
        "\n",
        "    full_transcript = \" \".join([part['text'] for part in transcript.fetch()])\n",
        "\n",
        "    # Save the transcript to a PDF file\n",
        "    save_to_pdf(full_transcript, language_code, output_pdf_path)\n",
        "\n",
        "    return full_transcript, language_code  # Return both the transcript and detected language"
      ],
      "metadata": {
        "id": "UnFxxu8ANfqR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_pdf(transcript, language_code, output_pdf_path):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "    pdf.cell(200, 10, txt=f\"Language Code: {language_code}\", ln=True, align='C')\n",
        "    pdf.ln(10)\n",
        "\n",
        "    pdf.multi_cell(0, 10, txt=transcript)\n",
        "\n",
        "    pdf.output(output_pdf_path)"
      ],
      "metadata": {
        "id": "dCOZv0fVNsU5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement Summarizer**"
      ],
      "metadata": {
        "id": "rPrc4Ir_PueT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install PyMuPDF"
      ],
      "metadata": {
        "id": "dk66NhdZPpAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers\n",
        "%pip install pytorch"
      ],
      "metadata": {
        "id": "SYIp8gHFP5uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with fitz.open(pdf_path) as doc:\n",
        "            for page_num in range(doc.page_count):\n",
        "                page = doc[page_num]\n",
        "                text += page.get_text()\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text: {str(e)}\")\n",
        "    return text"
      ],
      "metadata": {
        "id": "RlI_Y3mXPzix"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration"
      ],
      "metadata": {
        "id": "XMpR5MewP4Dp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")"
      ],
      "metadata": {
        "id": "yYTx0-NfP9a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text- text of transcript"
      ],
      "metadata": {
        "id": "G-vihigXQUoy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary_t5(text, tokenizer,model):\n",
        "\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=1000, min_length=600, length_penalty=1.0, num_beams=4, early_stopping=True)\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    output_pdf_path=\"summary.pdf\"\n",
        "    tr,langcode=get_transcript(url, output_pdf_path)\n",
        "\n",
        "    save_to_pdf(summary, langcode , output_pdf_path)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "gpi6wel7QDwf"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download Video**"
      ],
      "metadata": {
        "id": "VD0ucLd_T7_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pytube"
      ],
      "metadata": {
        "id": "l7u6u8RPT6bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "import re\n",
        "\n",
        "def clean_filename(title):\n",
        "    # Remove special characters and replace spaces with underscores\n",
        "    cleaned_title = re.sub(r'[^\\w\\s]', '', title)\n",
        "    cleaned_title = cleaned_title.replace(' ', '_')\n",
        "    return cleaned_title\n",
        "\n",
        "def download_youtube_video(video_url, output_path='.'):\n",
        "    try:\n",
        "        # Create a YouTube object\n",
        "        yt = YouTube(video_url)\n",
        "\n",
        "        # Get the highest resolution stream\n",
        "        video_stream = yt.streams.get_highest_resolution()\n",
        "\n",
        "        # Download the video\n",
        "        cleaned_title = clean_filename(yt.title)\n",
        "        print(f\"Downloading: {cleaned_title}\")\n",
        "        video_stream.download(output_path, filename=cleaned_title)\n",
        "        print(\"Download complete\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "metadata": {
        "id": "FIsmYDusTNKS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_youtube_video(\"https://www.youtube.com/watch?v=reUZRyXxUs4\", output_path='.')"
      ],
      "metadata": {
        "id": "zv3yl-EkUJG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running Functions**"
      ],
      "metadata": {
        "id": "Fdo4sDziXXoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_pdf_path = \"transcript_output.pdf\"\n",
        "url=input(\"Enter the url of the video\")\n",
        "get_transcript(url, output_pdf_path)\n",
        "text = extract_text_from_pdf(output_pdf_path)\n",
        "summary = generate_summary_t5(text,tokenizer,model)\n",
        "summary"
      ],
      "metadata": {
        "id": "QgtUlNuJWOHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JfvglKJEXQKj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}