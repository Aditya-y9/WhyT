{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzwZ23uOM+kYLJOEXxbW7w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kasodeep/inheritance-project/blob/main/final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrieve transcript**"
      ],
      "metadata": {
        "id": "IkrfTbj8Phgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf\n",
        "!pip install pytube\n",
        "!pip install youtube-transcript-api\n",
        "!pip install fpdf\n",
        "!pip install youtube_transcript_api"
      ],
      "metadata": {
        "id": "swzPfkGYPfH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea4320bd-6cbd-452b-e4fc-802347150f5d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2023.11.17)\n",
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: youtube_transcript_api in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_transcript_api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from fpdf import *"
      ],
      "metadata": {
        "id": "TSrb3c17NdWD"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect\n",
        "from langdetect import detect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcfK1BYLa4Ir",
        "outputId": "c8eb3ced-9090-48db-9bb4-c471d603d001"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lc=\"\"\n",
        "def get_transcript(youtube_url, output_pdf_path):\n",
        "    video_id = youtube_url.split(\"v=\")[-1]\n",
        "    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "\n",
        "    # Try fetching the manual transcript\n",
        "    try:\n",
        "        transcript = transcript_list.find_manually_created_transcript()\n",
        "        language_code = transcript.language_code  # Save the detected language\n",
        "        lc=language_code\n",
        "    except:\n",
        "        # If no manual transcript is found, try fetching an auto-generated transcript in a supported language\n",
        "        try:\n",
        "            generated_transcripts = [trans for trans in transcript_list if trans.is_generated]\n",
        "            transcript = generated_transcripts[0]\n",
        "            language_code = transcript.language_code  # Save the detected language\n",
        "            lc=language_code\n",
        "        except:\n",
        "            # If no auto-generated transcript is found, raise an exception\n",
        "            raise Exception(\"No suitable transcript found.\")\n",
        "\n",
        "    full_transcript = \" \".join([part['text'] for part in transcript.fetch()])\n",
        "\n",
        "    # Save the transcript to a PDF file\n",
        "    save_to_pdf(full_transcript, language_code, output_pdf_path)\n",
        "\n",
        "    return full_transcript, language_code  # Return both the transcript and detected language"
      ],
      "metadata": {
        "id": "UnFxxu8ANfqR"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_pdf(transcript, language_code, output_pdf_path):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "    pdf.cell(200, 10, txt=f\"Language Code: {language_code}\", ln=True, align='C')\n",
        "    pdf.ln(10)\n",
        "\n",
        "    pdf.multi_cell(0, 10, txt=transcript)\n",
        "\n",
        "    pdf.output(output_pdf_path)"
      ],
      "metadata": {
        "id": "dCOZv0fVNsU5"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement Summarizer**"
      ],
      "metadata": {
        "id": "rPrc4Ir_PueT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install PyMuPDF"
      ],
      "metadata": {
        "id": "dk66NhdZPpAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9af559d5-27fe-4388-ebea-53e0adcb9eb5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.23.20)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.9 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF) (1.23.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers\n",
        "%pip install pytorch"
      ],
      "metadata": {
        "id": "SYIp8gHFP5uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with fitz.open(pdf_path) as doc:\n",
        "            for page_num in range(doc.page_count):\n",
        "                page = doc[page_num]\n",
        "                text += page.get_text()\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text: {str(e)}\")\n",
        "    return text"
      ],
      "metadata": {
        "id": "RlI_Y3mXPzix"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration"
      ],
      "metadata": {
        "id": "XMpR5MewP4Dp"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")"
      ],
      "metadata": {
        "id": "yYTx0-NfP9a0"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text- text of transcript"
      ],
      "metadata": {
        "id": "G-vihigXQUoy"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary_t5(text, tokenizer,model):\n",
        "\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=1000, min_length=600, length_penalty=1.0, num_beams=4, early_stopping=True)\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    output_pdf_path=\"summary.pdf\"\n",
        "\n",
        "    save_to_pdf(summary, lc, \"output_summary.pdf\")\n",
        "\n",
        "\n",
        "    return summary"
      ],
      "metadata": {
        "id": "gpi6wel7QDwf"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download Video**"
      ],
      "metadata": {
        "id": "VD0ucLd_T7_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pytube"
      ],
      "metadata": {
        "id": "l7u6u8RPT6bO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c935bf02-99a7-4604-c324-18bf6107ab45"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "import re\n",
        "\n",
        "def clean_filename(title):\n",
        "    # Remove special characters and replace spaces with underscores\n",
        "    cleaned_title = re.sub(r'[^\\w\\s]', '', title)\n",
        "    cleaned_title = cleaned_title.replace(' ', '_')\n",
        "    return cleaned_title\n",
        "\n",
        "def download_youtube_video(video_url, output_path):\n",
        "    try:\n",
        "        # Create a YouTube object\n",
        "        yt = YouTube(video_url)\n",
        "\n",
        "        # Get the highest resolution stream\n",
        "        video_stream = yt.streams.get_highest_resolution()\n",
        "\n",
        "        # Download the video\n",
        "        cleaned_title = clean_filename(yt.title)\n",
        "        print(f\"Downloading: {cleaned_title}\")\n",
        "        video_stream.download(output_path, filename=cleaned_title)\n",
        "        print(\"Download complete\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "metadata": {
        "id": "FIsmYDusTNKS"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Images Slides pdf generation**"
      ],
      "metadata": {
        "id": "qPCHTK04YV23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers torchvision imagehash"
      ],
      "metadata": {
        "id": "G3IxJB_MYVYY"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from fpdf import FPDF\n",
        "from moviepy.editor import VideoFileClip\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
        "import torch\n",
        "from imagehash import phash\n",
        "import os"
      ],
      "metadata": {
        "id": "YNPDp0xdYeRZ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_feature_extractor = ViTFeatureExtractor.from_pretrained(\"JuanMa360/text-in-image-detection\")\n",
        "text_model = ViTForImageClassification.from_pretrained(\"JuanMa360/text-in-image-detection\")\n",
        "scene_model = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlkefxOXYj3d",
        "outputId": "7b55e824-72cd-408d-888e-5c93f573b694"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_text_probability(frame):\n",
        "    inputs_text = text_feature_extractor(images=frame, return_tensors=\"pt\")\n",
        "    outputs_text = text_model(**inputs_text)\n",
        "    logits_text = outputs_text.logits\n",
        "    probability_text = torch.nn.functional.softmax(logits_text, dim=1)[0, 2].item()\n",
        "    return probability_text\n",
        "\n",
        "def hash_image(image):\n",
        "    return phash(image)\n",
        "\n",
        "def classify_frames(frames, confidence_threshold_text=0.985, hash_threshold=10, confidence_threshold_scene=0.5, similarity_threshold=0.5):\n",
        "    processed_frames = set()\n",
        "    important_frames = []\n",
        "    for i, frame in enumerate(frames):\n",
        "\n",
        "        probability_text = compute_text_probability(frame)\n",
        "\n",
        "\n",
        "        if probability_text > confidence_threshold_text:\n",
        "            important_frames.append(frame)\n",
        "            image_hash = hash_image(frame)\n",
        "            processed_frames.add(image_hash)\n",
        "\n",
        "\n",
        "    for i in range(1, len(important_frames)):\n",
        "        current_frame = important_frames[i]\n",
        "        previous_frame = important_frames[i - 1]\n",
        "\n",
        "        similarity = 1.0 - (phash(current_frame) - phash(previous_frame)) / 64.0\n",
        "\n",
        "\n",
        "        if similarity < similarity_threshold:\n",
        "\n",
        "            important_frames.append(current_frame)\n",
        "\n",
        "\n",
        "    for frame in important_frames:\n",
        "        image_hash = hash_image(frame)\n",
        "\n",
        "\n",
        "        scene_probability = 0.0\n",
        "        if scene_model is not None:\n",
        "\n",
        "            scene_probability = 0.0\n",
        "\n",
        "        if scene_probability > confidence_threshold_scene:\n",
        "            processed_frames.add(image_hash)\n",
        "\n",
        "    return important_frames\n",
        "\n",
        "def extract_frames(video_path, num_frames=5):\n",
        "    clip = VideoFileClip(video_path)\n",
        "    frames = []\n",
        "\n",
        "    frame_interval = max(int(clip.fps * clip.duration) // num_frames, 5)\n",
        "\n",
        "    for i in range(0, int(clip.fps * clip.duration), frame_interval):\n",
        "        frame = clip.get_frame(i / clip.fps)\n",
        "        pil_image = Image.fromarray(frame.astype('uint8'), mode='RGB')\n",
        "        frames.append(pil_image)\n",
        "\n",
        "    return frames\n",
        "\n",
        "def generate_pdf(frames, output_pdf_path):\n",
        "    pdf = FPDF()\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "    for i in range(0, len(frames), 2):\n",
        "\n",
        "        pdf.add_page()\n",
        "\n",
        "\n",
        "        image_filename_1 = f\"frame_{i + 1}.png\"\n",
        "        frames[i].save(image_filename_1, format='PNG')\n",
        "\n",
        "        available_width = pdf.w - 30  # 15 units margin on both sides\n",
        "        available_height = pdf.h - 30  # 15 units margin on both top and bottom\n",
        "\n",
        "        # Calculate the aspect ratio of the images\n",
        "        aspect_ratio_1 = frames[i].width / frames[i].height\n",
        "\n",
        "        # Calculate the width and height of the first image to fit the available space\n",
        "        width_1 = min(available_width, frames[i].width)\n",
        "        height_1 = width_1 / aspect_ratio_1\n",
        "\n",
        "        # Calculate the x and y positions for the first image\n",
        "        x_1 = 15  # Left margin\n",
        "        y_1 = 15  # Top margin\n",
        "\n",
        "        # Add the first image\n",
        "        pdf.image(image_filename_1, x=x_1, y=y_1, w=width_1, h=height_1)\n",
        "        os.remove(image_filename_1)\n",
        "\n",
        "        # Add the second image if available\n",
        "        if i + 1 < len(frames):\n",
        "            image_filename_2 = f\"frame_{i + 2}.png\"\n",
        "            frames[i + 1].save(image_filename_2, format='PNG')\n",
        "\n",
        "            # Calculate the width and height of the second image to fit the available space\n",
        "            width_2 = min(available_width, frames[i + 1].width)\n",
        "            height_2 = width_2 / aspect_ratio_1  # Use the same aspect ratio as the first image\n",
        "\n",
        "            # Calculate the x and y positions for the second image\n",
        "            x_2 = 15  # Left margin\n",
        "            y_2 = y_1 + height_1  # Place the second image below the first\n",
        "\n",
        "            # Add the second image\n",
        "            pdf.image(image_filename_2, x=x_2, y=y_2, w=width_2, h=height_2)\n",
        "            os.remove(image_filename_2)\n",
        "\n",
        "    pdf.output(output_pdf_path)"
      ],
      "metadata": {
        "id": "xdfBs-LiYn-2"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def images(video_path,output_pdf_path):\n",
        "    frames = extract_frames(video_path, num_frames=20)\n",
        "    important_frames = classify_frames(frames)\n",
        "    if important_frames:\n",
        "        generate_pdf(important_frames, output_pdf_path)\n",
        "        print(f\"PDF generated successfully at {output_pdf_path}\")\n",
        "    else:\n",
        "        print(\"No important frames found.\")"
      ],
      "metadata": {
        "id": "EtnU2zxAeGmv"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running Functions**"
      ],
      "metadata": {
        "id": "Fdo4sDziXXoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run(url):\n",
        "    get_transcript(url,\"transcript_output.pdf\")\n",
        "    text = extract_text_from_pdf(\"transcript_output.pdf\")\n",
        "    summary = generate_summary_t5(text,tokenizer,model)\n",
        "    download_youtube_video(url,'video.mp4')\n",
        "    video_path = r\"/content/video.mp4/How_AI_Could_Empower_Any_Business__Andrew_Ng__TED\"\n",
        "    images(video_path,'slides.pdf')"
      ],
      "metadata": {
        "id": "JfvglKJEXQKj"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url=input('Enter the url of video')\n",
        "run(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0QF8VPZXYxk",
        "outputId": "111536bc-1ee7-4153-9326-5c1fcceee346"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the url of videohttps://www.youtube.com/watch?v=reUZRyXxUs4&t=544s\n",
            "Downloading: How_AI_Could_Empower_Any_Business__Andrew_Ng__TED\n",
            "Download complete\n",
            "PDF generated successfully at slides.pdf\n"
          ]
        }
      ]
    }
  ]
}