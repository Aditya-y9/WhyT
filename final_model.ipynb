{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsyngr+Ld7kaxWnwTW+xGA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kasodeep/inheritance-project/blob/main/final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrieve transcript**"
      ],
      "metadata": {
        "id": "IkrfTbj8Phgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf\n",
        "!pip install pytube\n",
        "!pip install youtube-transcript-api\n",
        "!pip install fpdf\n",
        "!pip install youtube_transcript_api"
      ],
      "metadata": {
        "id": "swzPfkGYPfH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a277759-e42d-4ab2-ec34-51508ec48626"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40703 sha256=2e66341a77d55e62befe971710da5af9e49bc49ef512555c2d5f2b50f5bb8617\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2023.11.17)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.6.2\n",
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: youtube_transcript_api in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_transcript_api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from fpdf import *"
      ],
      "metadata": {
        "id": "TSrb3c17NdWD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect\n",
        "from langdetect import detect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcfK1BYLa4Ir",
        "outputId": "468f414b-b678-483d-c758-8b84de5b5666"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=3cdc1d8c71bfa73b72227310e0978026288604cec8483ffedd1e357345fa0846\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lc=\"\"\n",
        "def get_transcript(youtube_url, output_pdf_path):\n",
        "    video_id = youtube_url.split(\"v=\")[-1]\n",
        "    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "\n",
        "    # Try fetching the manual transcript\n",
        "    try:\n",
        "        transcript = transcript_list.find_manually_created_transcript()\n",
        "        language_code = transcript.language_code  # Save the detected language\n",
        "        lc=language_code\n",
        "    except:\n",
        "        # If no manual transcript is found, try fetching an auto-generated transcript in a supported language\n",
        "        try:\n",
        "            generated_transcripts = [trans for trans in transcript_list if trans.is_generated]\n",
        "            transcript = generated_transcripts[0]\n",
        "            language_code = transcript.language_code  # Save the detected language\n",
        "            lc=language_code\n",
        "        except:\n",
        "            # If no auto-generated transcript is found, raise an exception\n",
        "            raise Exception(\"No suitable transcript found.\")\n",
        "\n",
        "    full_transcript = \" \".join([part['text'] for part in transcript.fetch()])\n",
        "\n",
        "    # Save the transcript to a PDF file\n",
        "    save_to_pdf(full_transcript, language_code, output_pdf_path)\n",
        "\n",
        "    return full_transcript, language_code  # Return both the transcript and detected language"
      ],
      "metadata": {
        "id": "UnFxxu8ANfqR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_pdf(transcript, language_code, output_pdf_path):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "    pdf.cell(200, 10, txt=f\"Language Code: {language_code}\", ln=True, align='C')\n",
        "    pdf.ln(10)\n",
        "\n",
        "    pdf.multi_cell(0, 10, txt=transcript)\n",
        "\n",
        "    pdf.output(output_pdf_path)"
      ],
      "metadata": {
        "id": "dCOZv0fVNsU5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement Summarizer**"
      ],
      "metadata": {
        "id": "rPrc4Ir_PueT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install PyMuPDF"
      ],
      "metadata": {
        "id": "dk66NhdZPpAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d32556-3894-4baf-9ebd-50ac7ee40330"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.23.20-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.23.9 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.23.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.23.20 PyMuPDFb-1.23.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers\n",
        "%pip install pytorch"
      ],
      "metadata": {
        "id": "SYIp8gHFP5uq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3bd1b16-af11-4ae9-ce72-7b652427b264"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Collecting pytorch\n",
            "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pytorch\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for pytorch\n",
            "Failed to build pytorch\n",
            "\u001b[31mERROR: Could not build wheels for pytorch, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with fitz.open(pdf_path) as doc:\n",
        "            for page_num in range(doc.page_count):\n",
        "                page = doc[page_num]\n",
        "                text += page.get_text()\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text: {str(e)}\")\n",
        "    return text"
      ],
      "metadata": {
        "id": "RlI_Y3mXPzix"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration"
      ],
      "metadata": {
        "id": "XMpR5MewP4Dp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")"
      ],
      "metadata": {
        "id": "yYTx0-NfP9a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text- text of transcript"
      ],
      "metadata": {
        "id": "G-vihigXQUoy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary_t5(text, tokenizer,model):\n",
        "\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=1000, min_length=600, length_penalty=1.0, num_beams=4, early_stopping=True)\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    output_pdf_path=\"summary.pdf\"\n",
        "\n",
        "    save_to_pdf(summary, lc, \"output_summary.pdf\")\n",
        "\n",
        "\n",
        "    return summary"
      ],
      "metadata": {
        "id": "gpi6wel7QDwf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download Video**"
      ],
      "metadata": {
        "id": "VD0ucLd_T7_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pytube"
      ],
      "metadata": {
        "id": "l7u6u8RPT6bO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "018bc64f-0b04-4e45-87a8-0a92e7e6a6c3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "import re\n",
        "\n",
        "def clean_filename(title):\n",
        "    # Remove special characters and replace spaces with underscores\n",
        "    cleaned_title = re.sub(r'[^\\w\\s]', '', title)\n",
        "    cleaned_title = cleaned_title.replace(' ', '_')\n",
        "    return cleaned_title\n",
        "\n",
        "def download_youtube_video(video_url, output_path):\n",
        "    try:\n",
        "        # Create a YouTube object\n",
        "        yt = YouTube(video_url)\n",
        "\n",
        "        # Get the highest resolution stream\n",
        "        video_stream = yt.streams.get_highest_resolution()\n",
        "\n",
        "        # Download the video\n",
        "        cleaned_title = clean_filename(yt.title)\n",
        "        print(f\"Downloading: {cleaned_title}\")\n",
        "        video_path = video_stream.download(output_path, filename=cleaned_title)\n",
        "        print(\"Download complete\")\n",
        "\n",
        "        return video_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "FIsmYDusTNKS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Images Slides pdf generation**"
      ],
      "metadata": {
        "id": "qPCHTK04YV23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers torchvision imagehash"
      ],
      "metadata": {
        "id": "G3IxJB_MYVYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from fpdf import FPDF\n",
        "from moviepy.editor import VideoFileClip\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
        "import torch\n",
        "from imagehash import phash\n",
        "import os"
      ],
      "metadata": {
        "id": "YNPDp0xdYeRZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_feature_extractor = ViTFeatureExtractor.from_pretrained(\"JuanMa360/text-in-image-detection\")\n",
        "text_model = ViTForImageClassification.from_pretrained(\"JuanMa360/text-in-image-detection\")\n",
        "scene_model = None"
      ],
      "metadata": {
        "id": "OlkefxOXYj3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_text_probability(frame):\n",
        "    inputs_text = text_feature_extractor(images=frame, return_tensors=\"pt\")\n",
        "    outputs_text = text_model(**inputs_text)\n",
        "    logits_text = outputs_text.logits\n",
        "    probability_text = torch.nn.functional.softmax(logits_text, dim=1)[0, 2].item()\n",
        "    return probability_text\n",
        "\n",
        "def hash_image(image):\n",
        "    return phash(image)\n",
        "\n",
        "def classify_frames(frames, confidence_threshold_text=0.985, hash_threshold=10, confidence_threshold_scene=0.5, similarity_threshold=0.5):\n",
        "    processed_frames = set()\n",
        "    important_frames = []\n",
        "    for i, frame in enumerate(frames):\n",
        "\n",
        "        probability_text = compute_text_probability(frame)\n",
        "\n",
        "\n",
        "        if probability_text > confidence_threshold_text:\n",
        "            important_frames.append(frame)\n",
        "            image_hash = hash_image(frame)\n",
        "            processed_frames.add(image_hash)\n",
        "\n",
        "\n",
        "    for i in range(1, len(important_frames)):\n",
        "        current_frame = important_frames[i]\n",
        "        previous_frame = important_frames[i - 1]\n",
        "\n",
        "        similarity = 1.0 - (phash(current_frame) - phash(previous_frame)) / 64.0\n",
        "\n",
        "\n",
        "        if similarity < similarity_threshold:\n",
        "\n",
        "            important_frames.append(current_frame)\n",
        "\n",
        "\n",
        "    for frame in important_frames:\n",
        "        image_hash = hash_image(frame)\n",
        "\n",
        "\n",
        "        scene_probability = 0.0\n",
        "        if scene_model is not None:\n",
        "\n",
        "            scene_probability = 0.0\n",
        "\n",
        "        if scene_probability > confidence_threshold_scene:\n",
        "            processed_frames.add(image_hash)\n",
        "\n",
        "    return important_frames\n",
        "\n",
        "def extract_frames(video_path, num_frames=5):\n",
        "    clip = VideoFileClip(video_path)\n",
        "    frames = []\n",
        "\n",
        "    frame_interval = max(int(clip.fps * clip.duration) // num_frames, 5)\n",
        "\n",
        "    for i in range(0, int(clip.fps * clip.duration), frame_interval):\n",
        "        frame = clip.get_frame(i / clip.fps)\n",
        "        pil_image = Image.fromarray(frame.astype('uint8'), mode='RGB')\n",
        "        frames.append(pil_image)\n",
        "\n",
        "    return frames\n",
        "\n",
        "def generate_pdf(frames, output_pdf_path):\n",
        "    pdf = FPDF()\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "    for i in range(0, len(frames), 2):\n",
        "\n",
        "        pdf.add_page()\n",
        "\n",
        "\n",
        "        image_filename_1 = f\"frame_{i + 1}.png\"\n",
        "        frames[i].save(image_filename_1, format='PNG')\n",
        "\n",
        "        available_width = pdf.w - 30  # 15 units margin on both sides\n",
        "        available_height = pdf.h - 30  # 15 units margin on both top and bottom\n",
        "\n",
        "        # Calculate the aspect ratio of the images\n",
        "        aspect_ratio_1 = frames[i].width / frames[i].height\n",
        "\n",
        "        # Calculate the width and height of the first image to fit the available space\n",
        "        width_1 = min(available_width, frames[i].width)\n",
        "        height_1 = width_1 / aspect_ratio_1\n",
        "\n",
        "        # Calculate the x and y positions for the first image\n",
        "        x_1 = 15  # Left margin\n",
        "        y_1 = 15  # Top margin\n",
        "\n",
        "        # Add the first image\n",
        "        pdf.image(image_filename_1, x=x_1, y=y_1, w=width_1, h=height_1)\n",
        "        os.remove(image_filename_1)\n",
        "\n",
        "        # Add the second image if available\n",
        "        if i + 1 < len(frames):\n",
        "            image_filename_2 = f\"frame_{i + 2}.png\"\n",
        "            frames[i + 1].save(image_filename_2, format='PNG')\n",
        "\n",
        "            # Calculate the width and height of the second image to fit the available space\n",
        "            width_2 = min(available_width, frames[i + 1].width)\n",
        "            height_2 = width_2 / aspect_ratio_1  # Use the same aspect ratio as the first image\n",
        "\n",
        "            # Calculate the x and y positions for the second image\n",
        "            x_2 = 15  # Left margin\n",
        "            y_2 = y_1 + height_1  # Place the second image below the first\n",
        "\n",
        "            # Add the second image\n",
        "            pdf.image(image_filename_2, x=x_2, y=y_2, w=width_2, h=height_2)\n",
        "            os.remove(image_filename_2)\n",
        "\n",
        "    pdf.output(output_pdf_path)"
      ],
      "metadata": {
        "id": "xdfBs-LiYn-2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def images(video_path,output_pdf_path):\n",
        "    frames = extract_frames(video_path, num_frames=20)\n",
        "    important_frames = classify_frames(frames)\n",
        "    if important_frames:\n",
        "        generate_pdf(important_frames, output_pdf_path)\n",
        "        print(f\"PDF generated successfully at {output_pdf_path}\")\n",
        "    else:\n",
        "        print(\"No important frames found.\")"
      ],
      "metadata": {
        "id": "EtnU2zxAeGmv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running Functions**"
      ],
      "metadata": {
        "id": "Fdo4sDziXXoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run(url):\n",
        "    get_transcript(url,\"transcript_output.pdf\")\n",
        "    text = extract_text_from_pdf(\"transcript_output.pdf\")\n",
        "    summary = generate_summary_t5(text,tokenizer,model)\n",
        "    video_path=download_youtube_video(url,'video.mp4')\n",
        "    images(video_path,'slides.pdf')"
      ],
      "metadata": {
        "id": "JfvglKJEXQKj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url=input('Enter the url of video')\n",
        "run(url) #https://www.youtube.com/watch?v=reUZRyXxUs4&t=544s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0QF8VPZXYxk",
        "outputId": "a7ee2aa0-5e88-43a0-a64a-98c631ac519f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the url of videohttps://www.youtube.com/watch?v=reUZRyXxUs4&t=544s\n",
            "Downloading: How_AI_Could_Empower_Any_Business__Andrew_Ng__TED\n",
            "Download complete\n",
            "PDF generated successfully at slides.pdf\n"
          ]
        }
      ]
    }
  ]
}