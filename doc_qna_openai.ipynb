{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1BuUSBKJyuQMZVvLShzvbnayfdmq5VoVo",
      "authorship_tag": "ABX9TyOO9Ig1dyi55v/XQTgKJqdc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kasodeep/inheritance-project/blob/main/doc_qna_openai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDQBcpE5lj-c"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "import os\n",
        "import openai\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain import OpenAI, VectorDBQA\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: pip install langchain , openai\n",
        "\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install unstructured"
      ],
      "metadata": {
        "id": "yZqAQ_-omAF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured[pdf]"
      ],
      "metadata": {
        "id": "Wgew-ipVnQUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import unstructured pdf loader\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "loader = UnstructuredFileLoader(\"/content/drive/MyDrive/lang_chains_data/transcript_output (1).pdf\")#Enter the path to your transcript pdf\n",
        "documents= loader.load()"
      ],
      "metadata": {
        "id": "itiqnFvelqHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "Iv2No4zHnbKV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHjmyo80pKuF",
        "outputId": "480a9d1e-e581-424a-d500-5609172eaa93"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "!pip install chromadb\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key = os.environ[\"OPENAI_API_KEY\"])\n",
        "doc_search = Chroma.from_documents(texts,embeddings)\n",
        "chain = VectorDBQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", vectorstore=doc_search)"
      ],
      "metadata": {
        "id": "1fE3_Tt0nT9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What crisis is faced by pakistan\"\n",
        "chain.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "-QBJyXNzpYAg",
        "outputId": "dea9e7c6-0df6-4aaa-d70f-af4e542e803d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The crisis facing Pakistan is the escalating tensions and potential military conflict with Iran following a recent attack by Iranian forces on a militant group in Pakistan.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}