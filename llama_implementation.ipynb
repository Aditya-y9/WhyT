{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kasodeep/inheritance-project/blob/main/llama_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pH36pjU31gl"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install fpdf\n",
        "!pip install ctransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9-cND-36Lat"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import langchain\n",
        "from torch import cuda, bfloat16\n",
        "from fpdf import FPDF\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from time import time\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.document_loaders import TextLoader,PyPDFLoader, DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain,ConversationalRetrievalChain,StuffDocumentsChain\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.llms import CTransformers\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain import PromptTemplate, LLMChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rc5epbmc8kIz"
      },
      "outputs": [],
      "source": [
        "#loading downloaded llm suitable for local usage,temperature(entropy/randomness in answer):1e-2\n",
        "llm = CTransformers(model=r\"/content/drive/MyDrive/lang_chains_data/llama-2k.bin\", model_type=\"llama\", streaming=True,\n",
        "                    callbacks=[StreamingStdOutCallbackHandler()],\n",
        "                    config={'max_new_tokens':4096,'temperature':0.01, 'context_length':4096})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmWPAGnY7UW7"
      },
      "outputs": [],
      "source": [
        "def summary_generation(file_path):\n",
        "    # Map\n",
        "    # loader = PyPDFLoader(file_path)\n",
        "    # docs = loader.load()\n",
        "    map_template = \"\"\"The following is a set of documents\n",
        "    {docs}\n",
        "    Based on this list of docs, please identify the main themes and concepts\n",
        "    Expand the description of each topic and concept for 2-3 lines that should include its basic descriptions,key points and formulas if any.\n",
        "    Helpful Answer:\"\"\"\n",
        "    map_prompt = PromptTemplate.from_template(map_template)\n",
        "    map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
        "    # Reduce\n",
        "    reduce_template = \"\"\"The following is set of summaries:\n",
        "    {docs}\n",
        "    Take these and distill it into a final, consolidated summary of the main topics and concepts that should include definitions and formulas of the concepts.Mention all the key points and formulas related to a concept.\n",
        "    Expand the description of each topic and concept for 2-3 lines.\n",
        "    Helpful Answer:\"\"\"\n",
        "    reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
        "        # Run chain\n",
        "    reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
        "\n",
        "    # Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
        "    combine_documents_chain = StuffDocumentsChain(\n",
        "        llm_chain=reduce_chain, document_variable_name=\"docs\"\n",
        "    )\n",
        "\n",
        "    # Combines and iteravely reduces the mapped documents\n",
        "    reduce_documents_chain = ReduceDocumentsChain(\n",
        "        # This is final chain that is called.\n",
        "        combine_documents_chain=combine_documents_chain,\n",
        "        # If documents exceed context for `StuffDocumentsChain`\n",
        "        collapse_documents_chain=combine_documents_chain,\n",
        "        # The maximum number of tokens to group documents into.\n",
        "        token_max=4000,\n",
        "    )\n",
        "        # Combining documents by mapping a chain over them, then combining results\n",
        "    map_reduce_chain = MapReduceDocumentsChain(\n",
        "        # Map chain\n",
        "        llm_chain=map_chain,\n",
        "        # Reduce chain\n",
        "        reduce_documents_chain=reduce_documents_chain,\n",
        "        # The variable name in the llm_chain to put the documents in\n",
        "        document_variable_name=\"docs\",\n",
        "        # Return the results of the map steps in the output\n",
        "        return_intermediate_steps=False,\n",
        "    )\n",
        "\n",
        "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
        "        chunk_size=500, chunk_overlap=50\n",
        "    )\n",
        "    split_docs = text_splitter.split_documents(docs)\n",
        "    all_summaries=map_reduce_chain.run(split_docs)\n",
        "    print(all_summaries)\n",
        "\n",
        "    return all_summaries\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summary_generation(file_path)"
      ],
      "metadata": {
        "id": "4Niho_c2MKtR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1IlgRtzgxtfeOyZoEKpK4BVtDuCYxpVOj",
      "authorship_tag": "ABX9TyPbZQsfhfH48m1zxRa+M8d6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}